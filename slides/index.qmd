---
title: "Introduction to machine learning with {tidymodels} in R"
subtitle: "RSS International Conference 2024"
author: "Nicola Rennie"
format:
  LUstyle-revealjs:
    self-contained: true
    footer: "[nrennie.rbind.io/rss-2024-tidymodels](https://nrennie.rbind.io/rss-2024-tidymodels)"
---

# Welcome!

## What to expect during this workshop

The workshop will run for *80 minutes*.

* Combines slides, live coding examples, and exercises for you to participate in.

* Ask questions throughout!

## What to expect during this workshop

::: columns
::: {.column}

<br>

I hope you end up with more questions than answers after this workshop!

:::

::: {.column .center}

<br>

![](images/questions.gif){fig-align="center" fig-alt="Stranger Things questions gif" width=80%}

<small>Source: <a href="https://giphy.com/gifs/netflix-stranger-things-4-st4-cn7GcSZ1KWqO7CJw1B">giphy.com</a></small>

:::
:::


## Workshop resources

::: columns
::: {.column}

* GitHub: [github.com/nrennie/rss-2024-tidymodels](https://github.com/nrennie/rss-2024-tidymodels)

* Slides: [nrennie.github.io/rss-2024-tidymodels](https://nrennie.github.io/rss-2024-tidymodels)

:::
::: {.column}

![](images/qr-code-slides.png){fig-align="center" fig-alt="QR code" width=70%}

:::

:::

## Requirements

* Access to R on your laptop or via [Posit Cloud](https://posit.cloud/).

* Installed the following packages:

  * tidymodels
  * glmnet
  * ranger
  * openintro (for data)
  * dplyr (optional)
  
## Data

We'll use data from the {openintro} R package:

```{r}
#| label: read-data-example
#| echo: true
#| eval: false
library(openintro) 
View(smoking)
View(resume)
```

# Getting started with \{tidymodels\} {background-color="#D9DBDB"}

## What is {tidymodels}?

::: columns
::: {.column}

* A collection of R packages for statistical modelling and machine learning.

* Follows the {tidyverse} principles.

* `install.packages("tidymodels")`

:::

::: {.column}

![](images/tidymodels.png){fig-align="center" fig-alt="tidymodels R package hex sticker logo" width=50%}

:::
:::

## What is {tidymodels}?

::: columns

::: {.column}

There are some core {tidymodels} packages...

<br>

... and plenty of extensions!

:::

::: {.column .center}

![](images/tidymodels-pkgs.png){fig-align="center" fig-alt="tidymodels packages hex sticker logo" width=100%} 

<small>Source: <a href="https://rpubs.com/chenx/tidymodels_tutorial">rpubs.com/chenx/tidymodels_tutorial</a></small>

:::

:::

# Before we start fitting models... {background-color="#D9DBDB"}

## Types of machine learning

::: columns

::: {.column}

**Supervised learning**: requires labelled input data

* Classification

* Regression-based models

* ...

:::

::: {.column}

**Unsupervised learning**: does not require labelled input data

* Clustering

* Association rules

* ...

:::

:::

Other types of machine learning include *semi-supervised learning* and *reinforcement learning*.

## Training and testing data

![](images/TrainTest.png){fig-align="center" fig-alt="Training and testing diagram" width=70%} 

## Hyperparameter tuning

::: columns

::: {.column width="30%"}

We can't always learn every parameter from the data.

:::

::: {.column .fragment width="70%"}

![](images/kfold.jpg){fig-align="center" fig-alt="kfold validation" width=70%} 

<small>Source: <a href="https://www.researchgate.net/publication/332370436_Introduction_to_Support_Vector_Machines_and_Kernel_Methods">Introduction to Support Vector Machines and Kernel Methods. Ashfaque and Iqbal. 2019.</a></small>

:::

:::

## Workflows and recipes

::: columns

::: {.column width="30%"}

![](images/recipes.png){fig-align="center" fig-alt="recipes package hex sticker" width=80%} 

:::

::: {.column width="70%"}

**Recipe**

A series of preprocessing steps performed on data before you fit a model.

<br>

**Workflow**

An object that can combine your pre-processing, modelling, and post-processing steps. E.g. combine a `recipe` with a model.


:::

:::

## Pre-processing in {tidymodels}

### Live demo!

<br><br>

::: {.fragment}

See `examples/example_01.R` for full code.

:::

## Exercise 1 

Open `exercises/exercise_01.R` for prompts.

* Load the `resume` data from {openintro}.

* Perform the initial split (choose your own proportion!).

* Create some cross-validation folds.

* Build a recipe and workflow. The outcome is `received_callback`.

```{r}
#| label: ex-1-timer
countdown::countdown(minutes = 5,
                    color_border = "#b20e10",
                    color_text = "#b20e10",
                    color_running_text = "white",
                    color_running_background = "#b20e10",
                    color_finished_text = "#b20e10",
                    color_finished_background = "white",
                    top = 0,
                    margin = "1.2em",
                    font_size = "2em")
```

. . . 

See `exercise_solutions/exercise_solutions_01.R` on GitHub for full code.

# LASSO regression {background-color="#D9DBDB"}

## Linear and logistic regression models

Let's go back a little bit first... 

. . . 

::: columns

::: {.column}
**Linear regression**
```{r}
#| label: lin-reg
#| eval: false
#| echo: true
lm(y ~ x, data = model_data)
```

![](images/lasso_01.png){fig-align="center" fig-alt="Linear regression plot" width=70%}

:::

::: {.column .fragment}
**Logistic regression**

```{r}
#| label: log-reg
#| eval: false
#| echo: true
glm(y ~ x, family = "binomial", data = model_data)
```

![](images/lasso_02.png){fig-align="center" fig-alt="Linear regression plot" width=70%}

:::

:::

## LASSO regression

::: columns
::: {.column}

**Standard regression**: minimise distance between predicted and observed values

<br>

**Least Absolute Shrinkage and Selection Operator (LASSO)**: minimise (distance between predicted and observed values + $\lambda$ $\times$ sum of coefficients)

<br>

See also: ridge regression

:::
::: {.column .fragment}

![](images/lambda.png){fig-align="center" fig-alt="Lambda plot for lasso regression" width=100%}

<small>Source: <a href="https://www.cvxpy.org/examples/machine_learning/lasso_regression.html">cvxpy.org/examples/machine_learning/lasso_regression.html</a></small>

:::
:::

## Hyperparameters for LASSO regression

**$\lambda$ (penalty)** takes a value between 0 and $\infty$.

* Higher value: more coefficients are pushed towards zero

* Lower value: closer to standard regression models. ($\lambda = 0$ ~ standard regression model)

## Model evaluation

::: columns
::: {.column}

**(Binary) Classification Metrics**

* Accuracy: proportion of the data that are predicted correctly.

* ROC AUC: area under the ROC (receiver operating characteristic) curve.

* Kappa: similar to accuracy but normalised by the accuracy expected by chance alone.

See [yardstick.tidymodels.org/articles/metric-types.html](https://yardstick.tidymodels.org/articles/metric-types.html).

:::
::: {.column .fragment .center}

![](images/roc.png){fig-align="center" fig-alt="ROC curve" width=100%}

<small>Source: <a href="https://commons.wikimedia.org/wiki/File:Roc-draft-xkcd-style.svg#filelinks">Martin Thoma (Wikipedia)</a></small>
:::
:::

## LASSO logistic regression in {tidymodels}

### Live demo!

<br><br>

::: {.fragment}

See `examples/example_02.R` for full code.

:::

## Exercise 2

Open `exercises/exercise_02.R` for prompts. You can also use `examples/example_02.R` as a starting point.

* Specify the model using `logistic_reg()`.

* Tune the hyperparameter.

* Choose the best value and fit the final model.

* Evaluate the model performance.

```{r}
#| label: ex-2-timer
countdown::countdown(minutes = 10,
                    color_border = "#b20e10",
                    color_text = "#b20e10",
                    color_running_text = "white",
                    color_running_background = "#b20e10",
                    color_finished_text = "#b20e10",
                    color_finished_background = "white",
                    top = 0,
                    margin = "1.2em",
                    font_size = "2em")
```

. . . 

See `exercise_solutions/exercise_solutions_02.R` for full code.

# Random Forests {background-color="#D9DBDB"}

## Decision trees

::: columns
::: {.column}

A tree-like model of decisions and their possible consequences.

:::
::: {.column}

![](images/rf_01.png){fig-align="center" fig-alt="Decision tree about walking to work and the weather" width=80%}

:::
:::

## What are Random Forests?

::: columns
::: {.column}

* An ensemble method

* Combines many decision trees.

* Can be used for classification or regression problems.

* For classification tasks, the output of the random forest is the class selected by most trees.

:::
::: {.column}

![](images/rf.png){fig-align="center" fig-alt="Random Forest diagram" width=100%}

<small>Source: <a href="https://en.m.wikipedia.org/wiki/File:Random_forest_explain.png">Tse Ki Chun (Wikimedia)</a></small>

:::
:::

## Hyperparameters for random forests

**trees**: number of trees in the ensemble.

<br>

**mtry**: number of predictors that will be randomly sampled at each split when creating the tree models.

<br>

**min_n**: minimum number of data points in a node that are required for the node to be split further.

## Random Forests in {tidymodels}

### Live demo!

<br><br>

::: {.fragment}

See `examples/example_03.R` for full code.

:::

## Exercise 3

Open `exercises/exercise_03.R` for prompts. You can also use `examples/example_03.R` as a starting point.

* Specify a random forest model using `rand_forest()`

* Tune the hyperparameters using the cross-validation folds.

* Fit the final model and evaluate it.

```{r}
#| label: ex-3-timer
countdown::countdown(minutes = 10,
                    color_border = "#b20e10",
                    color_text = "#b20e10",
                    color_running_text = "white",
                    color_running_background = "#b20e10",
                    color_finished_text = "#b20e10",
                    color_finished_background = "white",
                    top = 0,
                    margin = "1.2em",
                    font_size = "2em")
```

. . . 

See `exercise_solutions/exercise_solutions_03.R` for full code. 

# Additional Information {background-color="#D9DBDB"}

## Additional resources

::: columns

::: {.column}

<br>

* [{tidymodels} documentation](https://www.tidymodels.org/)

* [Tidy Modeling with R](https://www.tmwr.org/)

* [Blog by Julia Silge](https://juliasilge.com/blog/)

:::

::: {.column}

![](images/tmwr.png){fig-align="center" fig-alt="Tidy modelling with R cover" width=60%}

:::

:::

## Workshop resources

* GitHub: [github.com/nrennie/rss-2024-tidymodels](https://github.com/nrennie/rss-2024-tidymodels)

* Slides: [nrennie.rbind.io/rss-2024-tidymodels](https://nrennie.rbind.io/rss-2024-tidymodels)


## 

::: columns
::: {.column}

<br>

{{< fa brands linkedin >}} [nicola-rennie](https://www.linkedin.com/in/nicola-rennie/)

{{< fa brands mastodon >}} [fosstodon.org/\@nrennie](https://fosstodon.org/deck/@nrennie)

{{< fa brands github >}} [nrennie](https://github.com/nrennie)

{{< fa globe >}} [nrennie.rbind.io](https://nrennie.rbind.io/)


:::
::: {.column}

![](images/qr-code.png){fig-align="center" fig-alt="QR code" width=70%}

:::
:::
